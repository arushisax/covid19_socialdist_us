---
title: "covid_datacollection"
author: "Arushi Saxena"
date: "4/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Installing all the packages I might need for my Final Project below:
#install.packages("rvest")
#install.packages("tidytext")
#install_github("lchiffon/wordcloud2")
#install.packages("wordcloud2")
#install.packages("Rcpp")
#install.packages("rjson")
#install.packages("httpuv")
#install.packages("revgeo") #for reverse geocoding tweet location
#install.packages("mgsub") #to clean location data and replace strings
#install.packages("AlphaPart") #to turn tweets df into excel file
#installed.packages("SnowballC") #textmining
#installed.packages("tm")  #textmining
#installed.packages("syuzhet") #sentiment analysis

library(Rcpp)
library(dplyr)
library(ggplot2)
library(reprex)
library(tidyverse)
library(readxl)
library(rjson)
library(jsonlite)

```

# Scraping Twitter Data directly
```{r Twitter random scrape using Rtweet}
## Search for 18000 random tweets using the #socialdistancing hashtag 

## Store API keys from Twitter
api_key <- "5SP9pW4kckAMgSz1FD8htZssO"
api_secret_key <-"TJZkjzhc53piCXreADGSEDkz9tYACsWNExu7kXiGZxGCLaUFHd"

## Authenticate via web browser to use rtweet package
token <- create_token(
  app = "GOV1005 - Twitter & COVID-19",
  consumer_key = api_key,
  consumer_secret = api_secret_key)

get_token()

rt_041220 <- search_tweets(
  "social distancing", n = 18000, include_rts = FALSE, geocode = lookup_coords("usa"), retryonratelimit = TRUE
)

#Turn tweets into a dataframe
tweets_0412 <-as.data.frame(rt_041220)
tweets_0412

#Write dataframe into an RDS for later analysis
saveRDS(tweets_0412, file = "tweets_0412.rds")
tweets_0412_v2 <- readRDS(file = "tweets_0412.rds")

#Write dataframe into a CSV for analysis
write_as_csv(tweets_0412, "tweets_0412_v2.csv", prepend_ids = TRUE, na = "", fileEncoding = "UTF-8")

#Read in the Twitter CSV to analyze
tweets <- read_csv("Shiny_app/tweets_0412_v2.csv")
```

