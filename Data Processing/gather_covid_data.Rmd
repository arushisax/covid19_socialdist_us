---
title: "covid_datacollection"
author: "Arushi Saxena"
date: "4/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Installing all the packages I might need for my Final Project below:
#install.packages("rvest")
#install.packages("tidytext")
#install_github("lchiffon/wordcloud2")
#install.packages("wordcloud2")
#install.packages("Rcpp")
#install.packages("rjson")
#install.packages("httpuv")
#install.packages("revgeo") #for reverse geocoding tweet location
#install.packages("mgsub") #to clean location data and replace strings
#install.packages("AlphaPart") #to turn tweets df into excel file
#installed.packages("SnowballC") #textmining
#installed.packages("tm")  #textmining
#installed.packages("syuzhet") #sentiment analysis

library(Rcpp)
library(dplyr)
library(ggplot2)
library(reprex)
library(tidyverse)
library(readxl)
library(R.utils)


```

# Scraping Twitter Data directly
```{r Twitter random scrape using Rtweet}
## Search for 18000 random tweets using the #socialdistancing hashtag 

## Store API keys from Twitter
api_key <- "5SP9pW4kckAMgSz1FD8htZssO"
api_secret_key <-"TJZkjzhc53piCXreADGSEDkz9tYACsWNExu7kXiGZxGCLaUFHd"

## Authenticate via web browser to use rtweet package
token <- create_token(
  app = "GOV1005 - Twitter & COVID-19",
  consumer_key = api_key,
  consumer_secret = api_secret_key)

get_token()

rt_050520 <- search_tweets(
  "social distancing", n = 18000, include_rts = FALSE, geocode = lookup_coords("usa"), retryonratelimit = TRUE
)

#Turn tweets into a dataframe
tweets_0505 <-as.data.frame(rt_050520)
tweets_0505

# #Write dataframe into an RDS for later analysis
# saveRDS(tweets_0412, file = "tweets_0412.rds")
# tweets_0412_v2 <- readRDS(file = "tweets_0412.rds")

#Write dataframe into a CSV for analysis. The 0412 is my first Twitter data pull and the 0505 file is second Twitter data pull. I use 0412 for most of this analysis and only use 0505 data for the Geographic Analysis tab

write_as_csv(tweets_0412, "tweets_0412_v2.csv", prepend_ids = TRUE, na = "", fileEncoding = "UTF-8")

write_as_csv(tweets_0505, "tweets_0505.csv", prepend_ids = TRUE, na = "", fileEncoding = "UTF-8")

#Read in the Twitter CSV to analyze
tweets <- read_csv("Shiny_app/tweets_0412_v2.csv")
tweets_may <- read_csv("Shiny_app/tweets_0505.csv")
```

```{r downloading json zip file}
# https://www.stat.berkeley.edu/~paciorek/computingTips/Reading_gzipped_bzipped_zip.html


gunzip("data.json.gz", remove=FALSE)
us2 <- jsonlite::fromJSON("data.json")
us2
```
```

